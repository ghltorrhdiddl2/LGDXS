# detector/detection.py
import os
import time
import cv2
import requests
import numpy as np
from datetime import datetime
from pathlib import Path
from ultralytics import YOLO
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import google.generativeai as genai
import re
import warnings
import json

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore', category=UserWarning)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
SERVER_URL     = os.getenv("SERVER_URL", "http://localhost:8000")
API_EVENT_EP   = f"{SERVER_URL}/event"

# API í‚¤ ì§ì ‘ ì„¤ì •
GOOGLE_API_KEY = "AIzaSyAodNAwhpYmQkLWPA3dv-giw0WppjLhjMY"
genai.configure(api_key=GOOGLE_API_KEY)
LLM = genai.GenerativeModel(model_name="models/gemini-2.5-flash-preview-05-20")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[1]

# ===== ì…ë ¥ ì†ŒìŠ¤ ì„¤ì • =====
# ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Trueë¡œ ë³€ê²½
# ì˜ìƒ íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Falseë¡œ ì„¤ì •í•˜ê³  VIDEO_PATH ì§€ì •
USE_CAMERA = False  # True: ì¹´ë©”ë¼ ì‚¬ìš©, False: ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©
CAMERA_ID = 0  # ì¹´ë©”ë¼ ì‚¬ìš© ì‹œ ì¹´ë©”ë¼ ID
VIDEO_PATH = "videos/test_video2.mp4"  # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

# ===== íŒŒë¼ë¯¸í„° ì„¤ì • =====
"""
[ì˜ìƒ ì²˜ë¦¬ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
FRAME_SKIP = 5    # ëª‡ í”„ë ˆì„ë‹¹ 1ë²ˆ ì²˜ë¦¬í• ì§€ ì„¤ì •
                  # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬)
                  # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ìì£¼ ì²´í¬í•˜ì§€ë§Œ ì²˜ë¦¬ ë¶€í•˜ê°€ ì¦ê°€
                  # ê°’ì´ í´ìˆ˜ë¡ ì²˜ë¦¬ëŠ” ë¹ ë¥´ì§€ë§Œ ë†“ì¹˜ëŠ” í–‰ë™ì´ ë§ì•„ì§ˆ ìˆ˜ ìˆìŒ
                  # ê¶Œì¥ ë²”ìœ„: 3~10

WINDOW_SIZE = 5    # í•œ ë²ˆì— ë¶„ì„í•  í”„ë ˆì„ ë¬¶ìŒ í¬ê¸°
                   # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ë¬¶ìŒìœ¼ë¡œ ë¶„ì„
                   # FRAME_SKIPê³¼ ì—°ê³„ë˜ì–´ ì‹¤ì œ ì‹œê°„ ê³„ì‚°ë¨
                   # í˜„ì¬ ì„¤ì •: 5í”„ë ˆì„ Ã— 5í”„ë ˆì„ ê°„ê²© = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„

DETECTION_WINDOWS = 5    # ì´ìƒí–‰ë™ ê°ì§€ë¥¼ ìœ„í•´ ì²´í¬í•  ìœˆë„ìš° ìˆ˜
                        # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5ë²ˆì˜ ì—°ì†ëœ ìœˆë„ìš° ì²´í¬
                        # í˜„ì¬ ì„¤ì •: 5ë²ˆ Ã— 0.8ì´ˆ = ì•½ 4ì´ˆ ë™ì•ˆì˜ í–‰ë™ íŒ¨í„´ ì²´í¬

BUFFER_SECONDS = 4     # ì œë¯¸ë‹ˆ ë¶„ì„ ë° DB ì €ì¥ì„ ìœ„í•œ ì˜ìƒ ê¸¸ì´(ì´ˆ)
                      # ì œë¯¸ë‹ˆì— ë³´ë‚¼ ì˜ìƒê³¼ DBì— ì €ì¥í•  ì˜ìƒì˜ ê¸¸ì´
                      # ê°’ì´ í¬ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
                      # ê¶Œì¥ ë²”ìœ„: 3~5ì´ˆ

FPS = 30.0            # ê¸°ë³¸ FPS ì„¤ì •
                      # ëŒ€ë¶€ë¶„ì˜ ì¹´ë©”ë¼/ì˜ìƒì˜ ê¸°ë³¸ê°’ì´ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”

MAX_FRAMES = int(FPS * BUFFER_SECONDS)  # ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
                                       # ìë™ ê³„ì‚°ë˜ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”
                                       # í˜„ì¬ ì„¤ì •: 30fps Ã— 4ì´ˆ = 120í”„ë ˆì„

[ë¯¼ê°ë„ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
STD_MULTIPLIER = 0.5   # ì´ìƒí–‰ë™ ê°ì§€ ë¯¼ê°ë„
                      # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ë¯¼ê°í•˜ê²Œ ê°ì§€
                      # ê°’ì´ í´ìˆ˜ë¡ í™•ì‹¤í•œ ì´ìƒí–‰ë™ë§Œ ê°ì§€
                      # ê¶Œì¥ ë²”ìœ„: 0.3~1.0

IF_CONTAM = 0.2       # IsolationForest ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
LOF_CONTAM = 0.2      # LocalOutlierFactor ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
                      # ë‘ ê°’ì´ í´ìˆ˜ë¡ ë” ë§ì€ í–‰ë™ì„ ì´ìƒí–‰ë™ìœ¼ë¡œ íŒë‹¨
                      # ê¶Œì¥ ë²”ìœ„: 0.1~0.3

[ì‹¤ì œ ì‹œê°„ ê³„ì‚° ì˜ˆì‹œ]
í˜„ì¬ ì„¤ì • ê¸°ì¤€:
1. í”„ë ˆì„ ì²˜ë¦¬: 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ â†’ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€)
2. í–‰ë™ ë¶„ì„: 5í”„ë ˆì„ Ã— 5ë²ˆ = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„
3. ì´ìƒí–‰ë™ ê°ì§€: 5ë²ˆì˜ ì—°ì†ëœ ë¶„ì„ = ì•½ 4ì´ˆ ë™ì•ˆì˜ íŒ¨í„´ ì²´í¬
4. ì˜ìƒ ì €ì¥: ê°ì§€ í›„ 4ì´ˆ ë¶„ëŸ‰ ì €ì¥ ë° ë¶„ì„

ì„¤ì • ë³€ê²½ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ë¹ ë¥¸ ê°ì§€ê°€ í•„ìš”í•˜ë©´: FRAME_SKIPê³¼ WINDOW_SIZEë¥¼ ì¤„ì„
2. ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•˜ë©´: BUFFER_SECONDSë¥¼ ëŠ˜ë¦¼
3. ì €ì¥ ìš©ëŸ‰ ì ˆì•½ì´ í•„ìš”í•˜ë©´: FRAME_SKIPì„ ëŠ˜ë¦¼
"""

FRAME_SKIP         = 5    # 5í”„ë ˆì„ë‹¹ 1í”„ë ˆì„ ì²˜ë¦¬
WINDOW_SIZE        = 5    # ì´ìƒí–‰ë™ ê°ì§€ë¥¼ ìœ„í•œ ìœˆë„ìš° í¬ê¸° (5í”„ë ˆì„)
DETECTION_WINDOWS  = 5    # í•„ìš”í•œ ê°ì§€ íšŸìˆ˜ (5ë²ˆ)
ALLOWED_NORMAL     = 1    # í—ˆìš©ë˜ëŠ” ì •ìƒ í–‰ë™ íšŸìˆ˜
FPS               = 30.0  # ê¸°ë³¸ FPS
BUFFER_SECONDS    = 4     # ì €ì¥í•  ì˜ìƒ ê¸¸ì´ (ì´ˆ)
MAX_FRAMES        = int(FPS * BUFFER_SECONDS)  # ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
STD_MULTIPLIER    = 0.5   # í‘œì¤€í¸ì°¨ ë°°ìˆ˜ (ë¯¼ê°ë„)
IF_CONTAM         = 0.2   # IsolationForest contamination
LOF_CONTAM        = 0.2   # LocalOutlierFactor contamination
LOF_NEIGHBORS     = 4     # LocalOutlierFactor neighbors

# Gemini í”„ë¡¬í”„íŠ¸ â€“ 0~4ë‹¨ê³„ ëª…ì‹œ
dog_name = "ë³„ì´"
PROMPT = f"""ê°•ì•„ì§€ {dog_name}ì˜ í˜„ì¬ í–‰ë™ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
ê°•ì•„ì§€ì˜ ìì„¸ì™€ ì›€ì§ì„ì„ ê¸°ë°˜ìœ¼ë¡œ í–‰ë™ì„ í•´ì„í•˜ê³ , ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
1. í˜„ì¬ í–‰ë™ ì„¤ëª… (1ì¤„)
2. ëŒ€ì²˜ ë°©ë²• (1-2ì¤„)
3. ì‹¬ê°ë„: [0-4]ë‹¨ê³„
- 0ë‹¨ê³„: ì •ìƒì ì¸ í–‰ë™ (í‰ì˜¨, íœ´ì‹, ì¼ìƒì  í™œë™)
- 1ë‹¨ê³„: ì£¼ì˜ ê´€ì°° í•„ìš” (ê³¼ë„í•œ ì›€ì§ì„, ë¶ˆì•ˆí•œ ì§•í›„)
- 2ë‹¨ê³„: ê²½ë¯¸í•œ ë¬¸ì œ í–‰ë™ (ë°˜ë³µì ì¸ ì´ìƒ í–‰ë™)
- 3ë‹¨ê³„: ì‹¬ê°í•œ ë¬¸ì œ í–‰ë™ (ê³µê²©ì„±, ìí•´ ìœ„í—˜)
- 4ë‹¨ê³„: ì¦‰ê° ì¡°ì¹˜ í•„ìš” (ìœ„í—˜í•œ ìƒí™©)

* 3ë‹¨ê³„ ì´ìƒì¼ ê²½ìš° ì‘ë‹µì„ **êµµì€ ê¸€ì”¨**ë¡œ í‘œì‹œ
* ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ì˜ˆì˜ì  í‘œí˜„ì€ ìƒëµ
* ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” íŒŒì•…ì´ ì–´ë ¤ì›Œë„ ìµœëŒ€í•œ íŒŒì•…í•´ì„œ í–‰ë™ ë¶„ì„í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
* ë°˜ë“œì‹œ ë‹¨ê³„ë¥¼ ìˆ«ìë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš” (ì˜ˆ: '2ë‹¨ê³„' ë˜ëŠ” 'ë‹¨ê³„: 2')"""

# ëª¨ë¸ ë¡œë“œ
MODEL_PATH = PROJECT_ROOT / "dog_pose_model.pt"
print(f"ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
yolo      = YOLO(str(MODEL_PATH))
if_model  = IsolationForest(contamination=IF_CONTAM, random_state=42)
lof_model = LocalOutlierFactor(n_neighbors=LOF_NEIGHBORS, contamination=LOF_CONTAM, novelty=True)

def z_norm(a):
    return (a - a.mean()) / (a.std() or 1.0)

def post_event(timestamp, stage, summary, frames, fps):
    """
    ì„œë²„ /event ë¡œ ì´ë²¤íŠ¸ ë°ì´í„° ì „ì†¡ ë° ì €ì¥ í™•ì¸
    """
    try:
        if not frames:
            print("âš ï¸ ì €ì¥í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_name = f"{current_time}.avi"
        temp_path = os.path.join('temp_videos', video_name)
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('temp_videos', exist_ok=True)
        
        print(f"\nğŸ“ ì„ì‹œ íŒŒì¼ ìƒì„± ì¤‘: {temp_path}")
        
        h, w = frames[0].shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        out = cv2.VideoWriter(temp_path, fourcc, fps/FRAME_SKIP, (w, h))
        
        for frame in frames:
            if frame.shape[:2] != (h, w):
                frame = cv2.resize(frame, (w, h))
            out.write(frame)
        out.release()
        
        if not os.path.exists(temp_path):
            print("âš ï¸ ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return None
            
        file_size = os.path.getsize(temp_path)
        print(f"ğŸ“¤ ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡ ì¤‘... (íŒŒì¼ í¬ê¸°: {file_size/1024:.1f}KB)")
        
        # multipart/form-data í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡
        with open(temp_path, 'rb') as f:
            files = {'video_data': (video_name, f, 'video/avi')}
            data = {
                'timestamp': timestamp,
                'stage': str(stage),  # ë¬¸ìì—´ë¡œ ë³€í™˜
                'summary': summary
            }
            
            try:
                r = requests.post(API_EVENT_EP, data=data, files=files, timeout=30)
                print(f"   - ì„œë²„ ì‘ë‹µ ì½”ë“œ: {r.status_code}")
                print(f"   - ì„œë²„ ì‘ë‹µ ë‚´ìš©: {r.text}")
                
                if r.status_code == 200:
                    response = r.json()
                    if response.get('id'):
                        print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ!")
                        print(f"   - íŒŒì¼ëª…: {video_name}")
                        print(f"   - í”„ë ˆì„ ìˆ˜: {len(frames)}")
                        print(f"   - DB ID: {response['id']}")
                        return response
                    
                print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: ì„œë²„ ì‘ë‹µ í™•ì¸ í•„ìš”")
                return None
                    
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ HTTP ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
                return None
                
    except Exception as e:
        print(f"âš ï¸ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None
        
    finally:
        try:
            if os.path.exists(temp_path):
                os.remove(temp_path)
                print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œë¨: {temp_path}")
        except Exception as e:
            print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

def analyze_with_gemini(frames_count):
    """ì œë¯¸ë‹ˆë¥¼ ì‚¬ìš©í•œ í–‰ë™ ë¶„ì„ í•¨ìˆ˜"""
    try:
        print("\nğŸ¤– ì œë¯¸ë‹ˆ ë¶„ì„ ì‹œì‘...")
        
        # í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ ìƒí™© ì¶”ê°€
        analysis_prompt = f"""{PROMPT}

í˜„ì¬ ìƒí™©: 
- ê°•ì•„ì§€ê°€ {BUFFER_SECONDS}ì´ˆ ë™ì•ˆ ì—°ì†ì ìœ¼ë¡œ íŠ¹ì´í•œ í–‰ë™ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- ì´ {frames_count}ê°œì˜ í”„ë ˆì„ì—ì„œ ì´ìƒ í–‰ë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.
- ìì„¸í•œ ë¶„ì„ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤."""

        print("ğŸ“ í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì¤‘...")
        
        # ì œë¯¸ë‹ˆ API í˜¸ì¶œ
        resp = LLM.generate_content([analysis_prompt])
        
        if not resp:
            print("âš ï¸ ì œë¯¸ë‹ˆ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ"
            
        text = resp.text.strip()
        print("\nâœ… ì œë¯¸ë‹ˆ ì‘ë‹µ ë°›ìŒ:")
        print(text)
        
        # ë‹¨ê³„ ì¶”ì¶œ ì‹œë„
        stage = 0
        stage_match = re.search(r'(\d+)ë‹¨ê³„', text)
        if stage_match:
            stage = int(stage_match.group(1))
        else:
            # ë‹¤ë¥¸ í˜•ì‹ ì‹œë„ (ì˜ˆ: "ë‹¨ê³„: 2" ë˜ëŠ” "ì‹¬ê°ë„: 2")
            alt_match = re.search(r'ë‹¨ê³„:\s*(\d+)|ì‹¬ê°ë„:\s*(\d+)', text)
            if alt_match:
                stage = int(alt_match.group(1) or alt_match.group(2))
            else:
                # ë§ˆì§€ë§‰ ì‹œë„: ì²« ë²ˆì§¸ ìˆ«ì ì°¾ê¸°
                num_match = re.search(r'\d+', text)
                if num_match:
                    stage = int(num_match.group())
        
        if stage < 0 or stage > 4:
            print(f"âš ï¸ ì˜ëª»ëœ ë‹¨ê³„ ê°’ ({stage}) - 0ìœ¼ë¡œ ì„¤ì •")
            stage = 0
            
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"- ê°ì§€ëœ ë‹¨ê³„: {stage}")
        print(f"- ë¶„ì„ ê¸¸ì´: {len(text)} ë¬¸ì")
        
        return stage, text
        
    except Exception as e:
        print(f"\nâŒ ì œë¯¸ë‹ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        print(f"- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}")
        print(f"- ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
        import traceback
        print("- ìƒì„¸ ì˜¤ë¥˜:")
        print(traceback.format_exc())
        return 0, f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

def process_video():
    """
    ì˜ìƒ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ì½ì–´ ì²˜ë¦¬
    """
    print("ğŸ¥ ì˜ìƒ ì†ŒìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    
    if USE_CAMERA:
        # ì¹´ë©”ë¼ ëª¨ë“œ
        cap = cv2.VideoCapture(CAMERA_ID, cv2.CAP_DSHOW)
        if not cap.isOpened():
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        print(f"âœ… ì¹´ë©”ë¼ {CAMERA_ID} ì—°ê²°ë¨")
    else:
        # ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œ
        video_path = str(PROJECT_ROOT / VIDEO_PATH)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return
        print(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œë¨: {video_path}")
    
    # í•´ìƒë„ ì„¤ì • (ì¹´ë©”ë¼ ëª¨ë“œì¼ ë•Œë§Œ)
    if USE_CAMERA:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    # ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS) or FPS
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"- í•´ìƒë„: {width}x{height}")
    print(f"- FPS: {fps:.1f}")
    print(f"- í”„ë ˆì„ ìŠ¤í‚µ: {FRAME_SKIP} (ì²˜ë¦¬ FPS: {fps/FRAME_SKIP:.1f})")
    print(f"- ë²„í¼ í¬ê¸°: {BUFFER_SECONDS}ì´ˆ ({MAX_FRAMES} í”„ë ˆì„)")
    if not USE_CAMERA:
        print(f"- ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        print(f"- ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {total_frames/fps:.1f}ì´ˆ")

    # ì´ˆê¸°í™”
    features = []  # íŠ¹ì§•ì  ë²„í¼
    frames_vis = []  # ì‹œê°í™”ëœ í”„ë ˆì„ ë²„í¼
    frame_idxs = []  # í”„ë ˆì„ ì¸ë±ìŠ¤ ë²„í¼
    frame_no = 0
    last_event_time = 0
    is_recording = False
    current_stage = 0
    current_summary = ""
    
    # ì´ìƒí–‰ë™ ê°ì§€ ê´€ë ¨ ë³€ìˆ˜
    abnormal_windows = []  # ê° ìœˆë„ìš°ì˜ ì´ìƒí–‰ë™ ì—¬ë¶€ë¥¼ ì €ì¥
    continuous_detection = False  # ì—°ì† ê°ì§€ ìƒíƒœ
    
    cv2.namedWindow("Dog Pose Detection", cv2.WINDOW_NORMAL)

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âœ… ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
            break
            
        if frame is None or frame.size == 0:
            print("âš ï¸ ë¹ˆ í”„ë ˆì„ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            continue
            
        frame_no += 1
        current_time = time.time()
        
        # ì§„í–‰ë¥  í‘œì‹œ (ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œì¼ ë•Œë§Œ)
        if not USE_CAMERA and frame_no % 30 == 0:
            progress = (frame_no / total_frames) * 100
            print(f"\rì§„í–‰ë¥ : {progress:.1f}%", end="")
        
        if frame_no % FRAME_SKIP != 0:
            continue

        # YOLOë¡œ í¬ì¦ˆ ì˜ˆì¸¡ ë° ì‹œê°í™”
        result = yolo.predict(frame, conf=0.7, verbose=False)[0]
        vis = result.plot()

        if result.keypoints is not None and len(result.keypoints.data) > 0:
            kpts = result.keypoints.data[0]
            if kpts.shape[0] == 24:
                pelvis = kpts[14][:2]
                l_sh, r_sh = kpts[11][:2], kpts[12][:2]
                scale = np.linalg.norm(l_sh - r_sh) or 1.0

                feat = []
                for x, y, v in kpts:
                    if v < 0.5:
                        feat += [0.0, 0.0]
                    else:
                        feat += [(x - pelvis[0]) / scale,
                                (y - pelvis[1]) / scale]
                features.append(feat)
                frames_vis.append(vis.copy())
                frame_idxs.append(frame_no)

                # íŠ¹ì§•ì ì´ ì¶©ë¶„íˆ ëª¨ì´ë©´ ì´ìƒí–‰ë™ ê°ì§€
                if len(features) >= WINDOW_SIZE:
                    X = np.array(features[-WINDOW_SIZE:])
                    if_model.fit(X)
                    lof_model.fit(X)
                    if_scores = if_model.decision_function(X)
                    lof_scores = lof_model.decision_function(X)
                    combined = (z_norm(if_scores) + z_norm(lof_scores)) / 2.0
                    
                    # ì„ê³„ì¹˜ ê³„ì‚° ë° ì´ìƒí–‰ë™ íŒì •
                    threshold = combined.mean() - STD_MULTIPLIER * combined.std()
                    is_abnormal = combined[-1] < threshold

                    # í˜„ì¬ ìœˆë„ìš°ì˜ ì´ìƒí–‰ë™ ì—¬ë¶€ ì €ì¥
                    abnormal_windows.append(is_abnormal)
                    if len(abnormal_windows) > DETECTION_WINDOWS:
                        abnormal_windows.pop(0)

                    # ì—°ì†ëœ ì´ìƒí–‰ë™ ì²´í¬
                    if len(abnormal_windows) == DETECTION_WINDOWS:
                        abnormal_count = sum(abnormal_windows)
                        if abnormal_count >= (DETECTION_WINDOWS - ALLOWED_NORMAL) and not continuous_detection:
                            continuous_detection = True
                            is_recording = True
                            frames_vis = []  # ë²„í¼ ì´ˆê¸°í™”
                            print("\nğŸ” ì—°ì†ì ì¸ ì´ìƒí–‰ë™ ê°ì§€ - ì˜ìƒ ìˆ˜ì§‘ ì‹œì‘")
                    
                    # ì˜ìƒ ìˆ˜ì§‘ ë° ë¶„ì„
                    if is_recording:
                        if len(frames_vis) >= MAX_FRAMES:
                            print(f"\nğŸ“¹ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ ({len(frames_vis)} í”„ë ˆì„)")
                            
                            # ì œë¯¸ë‹ˆ ë¶„ì„ ì‹¤í–‰
                            current_stage, current_summary = analyze_with_gemini(len(frames_vis))
                            
                            # 0ë‹¨ê³„ê°€ ì•„ë‹ ë•Œë§Œ ì €ì¥
                            if current_stage > 0:
                                print(f"\nğŸ’¾ ì˜ìƒ ì €ì¥ ì‹œë„ ì¤‘... (ë‹¨ê³„: {current_stage})")
                                result = post_event(datetime.now().isoformat(), 
                                                  current_stage, 
                                                  current_summary, 
                                                  frames_vis, 
                                                  fps)
                                
                                if result:
                                    print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ!")
                                    print(f"   - í”„ë ˆì„ ìˆ˜: {len(frames_vis)}")
                                    print(f"   - ì˜ìƒ ê¸¸ì´: {BUFFER_SECONDS}ì´ˆ")
                                    print(f"   - í–‰ë™ ë‹¨ê³„: {current_stage}")
                                else:
                                    print("âš ï¸ ì´ë²¤íŠ¸ ì €ì¥ ì‹¤íŒ¨")
                            else:
                                print(f"\nâœ¨ ì •ìƒ í–‰ë™ìœ¼ë¡œ íŒë‹¨ë¨ (0ë‹¨ê³„) - ì˜ìƒ ì €ì¥í•˜ì§€ ì•ŠìŒ")
                            
                            # ìƒíƒœ ì´ˆê¸°í™”
                            frames_vis = []
                            is_recording = False
                            continuous_detection = False
                            abnormal_windows = []
                            current_stage = 0
                            current_summary = ""

                    # ë²„í¼ ê´€ë¦¬
                    if len(features) > WINDOW_SIZE:
                        features.pop(0)
                    if len(frames_vis) > MAX_FRAMES:
                        frames_vis.pop(0)
                    if len(frame_idxs) > MAX_FRAMES:
                        frame_idxs.pop(0)

        cv2.imshow("Dog Pose Detection", vis)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    process_video()
