{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92abeed-c909-43f1-914c-4b96b9aedb4e",
   "metadata": {},
   "source": [
    "### OpenCV는 \n",
    "- Computer Vision 관련 프로그래밍을 쉽게 할 수 있도록 도와주는 Open Library입니다. OpenCV는 영상처리, 3D 구성, 추적, 기계학습, 인식 그리고 딥러닝까지 유용한 기능이 아주 많습니다. 그리고 상업적인 사용까지 무료입니다. \n",
    "\n",
    "- OpenCV :  컴퓨터 비전 분야는 사람이 시각 정보를 입력값으로 하여 행동하기 이전에 생각하고 판단하는 부분을 컴퓨터가 대신하도록 하는 학문입니다. 쉽게 말해서 인공지능이라고 말할 수도 있겠습니다. 다만, 시각적인 입력 데이터, 즉 영상을 주로 다룬다는 것이 차이점입니다.\n",
    "\n",
    "- YOLO : 이미지 내에서 객체를 탐지할 때 사용하는 딥러닝 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af498cb-6f5f-46bb-85b8-3d545abdd928",
   "metadata": {},
   "source": [
    "#### 이미지 출력\n",
    "- 이미지(영상) 화면에 띄우기\n",
    "- 데이터 https://pixabay.com/ko/images/search/dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb59ec6-34c1-4428-bfb5-fd7a358d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv import >> cv2\n",
    "# cv 별도로 있어서 이름을 다르게 설정해둔 것\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5752ca-40e6-421c-9528-29b815f028a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽기\n",
    "img = cv2.imread('./data/puppy.jpg')\n",
    "cv2.imshow('puppy img', img) # 윈도우창 이름, 출력할 데이터 -> 새로운 창 출력\n",
    "cv2.waitKey(0)          # 사용자의 인풋을 기다리는 기능/ 키보드 \n",
    "cv2.destroyAllWindows() # 모든 창 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b1087-3be2-495e-b738-219d884c9c61",
   "metadata": {},
   "source": [
    "- 읽기 옵션\n",
    "\n",
    "- 1. cv2.IMREAD_COLOR: 컬러 이미지, 투명 영역은 무시(기본값)\n",
    "\n",
    "- 2. cv2.IMREAD_GRAYSCALE: 흑백 이미지\n",
    "\n",
    "- 3. cv2.IMREAD_UNCHANGED: 투명 영역까지 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bc5b4-531c-4865-802d-1d9f5543a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = cv2.imread('./data/puppy.jpg', cv2.IMREAD_COLOR)\n",
    "img_gry = cv2.imread('./data/puppy.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_unch = cv2.imread('./data/puppy.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "cv2.imshow('puppy color', img_color)\n",
    "cv2.imshow('puppy gray', img_gry)\n",
    "cv2.imshow('puppy unch', img_unch)\n",
    "key = cv2.waitKey(0)  # 지정된 시간동안 사용자 키 입력 대기 # 0: 무한대기, 5000ms -> 5초\n",
    "print(key)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3d0e6-8b95-448a-9bcf-56cc8b554749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알파벳을 아스키 코드 값으로 변형하는 기능\n",
    "ord('q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8ff56-f4a2-4991-90eb-1acee7060432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.waitKey(ms)\n",
    "# 0을 입력하여 무한 대기 상태로 표현, 사용자가 특정 키워드를 입력했을때 창을 끄거나 캡쳐하거나 상황에 따라 행동을 제어하게 할 수 있음(제어문- 조건문)\n",
    "\n",
    "# 5000ms : 5초 동안 화면이 띄워지고 5초 후에 꺼지게 하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e5f24-fcf6-4864-8d78-833ee929e3dc",
   "metadata": {},
   "source": [
    "#### 이미지의 크기 정보\n",
    "- shape: 행, 열, 채널의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965260b-4759-47c3-a4cd-66cd42030602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('color:', img_color.shape)  # 3차원\n",
    "print('gray:', img_gry.shape)     # 2차원\n",
    "print('unch:', img_unch.shape)    # 3차원(RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e51222-fcac-44ef-92e7-faf572aec2f1",
   "metadata": {},
   "source": [
    "#### cv2윈도우창 띄우지 않고, Matplotlib 시각화 도구 inline 상태로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3cb7ae-acf5-4097-8c08-fa796de08a52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_c_internal_utils' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\lgdxschool2\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m img_color \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/puppy.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 컬러 이미지 기본값\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)        \u001b[38;5;66;03m# 축 눈금 제거\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcsetup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\matplotlib\\cbook.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _c_internal_utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ExceptionInfo\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    A class to carry exception information around.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    users and result in incorrect tracebacks.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_c_internal_utils' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\lgdxschool2\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_color = cv2.imread('./data/puppy.jpg') # 컬러 이미지 기본값\n",
    "\n",
    "plt.axis('off')        # 축 눈금 제거\n",
    "# 눈금축이 있으면 좋을 때? - 좌표설정(그리거나 잘라낼 때 )\n",
    "plt.imshow(img_color)  \n",
    "plt.show()\n",
    "\n",
    "# 색상공간 BGR(옛날) -> RGB(현재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b989c-b7c3-4fc1-b702-796ef4ce1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_color = cv2.imread('./data/puppy.jpg')\n",
    "print(img_color[0,0])\n",
    "\n",
    "# 색상 변환하는 함수\n",
    "img_color2 = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
    "print(img_color2[0,0])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img_color2)  \n",
    "plt.show()\n",
    "\n",
    "# 색상공간 BGR(옛날) -> RGB(현재)\n",
    "# [19 37 36] -> [36 19 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98084bf0-9548-439f-a8d0-37be8705b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.title('BGR')\n",
    "plt.imshow(img_color)  \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.title('RGB')\n",
    "plt.imshow(img_color2) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2b0a1-e829-4587-8046-72a63bbbffa4",
   "metadata": {},
   "source": [
    "<색상공간 변환>\n",
    "- 시각은 색상정보에 대해 잘못된 정보를 보내주는 경우가 많음\n",
    "    - 밤에 색상을 볼때 정확한 색상을 보여주지 못함 - 명도 (검정색이 섞이는 것)\n",
    "    - 색상에 빛을 강하게 비추는 경우 정확한 색상을 보여주지 못함 - 채도 (흰색이 섞이는 것)\n",
    "    - 칼라는 너무 많은 정보를 가지고 있기때문에 연산량이 많음 - 실시간 처리가 어려움\n",
    "    - 따라서 gray 이미지나 binary 이미지로 변환해서 처리\n",
    "    - gray 이미지 : 0-255로 된 픽섹로만 구성된 흑백이미지\n",
    "    - 이진 이미지 : 검정색(0)과 흰색(255)으로만 구성된 이미지, 0과 1로 이루어진 이미지\n",
    "        - 특정 패턴이나 물체의 윤곽을 감지\n",
    "        - 배경/물체 구별\n",
    "        - 텍스트 필터링\n",
    "        - 뼈의 윤곽/mri스캔 종양 식별\n",
    "        - 자율주행시 장애물/차선 등 감지\n",
    "        - 제품 결함 및 불량품 식별 등 사용가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea08e2-c4a8-4a0d-b68d-6ae7c4f056af",
   "metadata": {},
   "source": [
    "- color -> gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10ab39-f654-426d-ab4c-ed0aa2e48879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1 : imread(, cv2.IMREAD_GRAYSCALE)\n",
    "img_gray = cv2.imread('./data/puppy.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9435d-df9f-4403-b4bc-4b3263ad3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2 : 이미지를 읽어혼 후에 cvtColor 그레이스케일로 변환\n",
    "# plt.imshow(img_color2)\n",
    "\n",
    "gray_img = cv2.cvtColor(img_color2, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.axis('off')  # plt.xticks([]); plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "print(img_color2.shape)\n",
    "print(gray_img.shape)\n",
    "# 차원의 크기 다름 == 데이터 크기 다름, 분석 모델의 연산량 (계산량, 학습량 ) 연관되는 내용\n",
    "# 컬러 이미지보다 흑백계열 이미지의 데이터 크기가 작음(데이터의 복잡도를 줄일 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafde98-534e-4f5f-aeca-fa53cde23dc7",
   "metadata": {},
   "source": [
    "- 머신러닝 2차원까지\n",
    "- 딥러닝 더 복잡한 학습 가능 2,3차원\n",
    "- 탐지하거나 고객 감성 살필 때 분석하는 내용의 정확도가 달라질 수 있음\n",
    "- 무조건 양이 작아진다고 좋은 것은 아님(데이터 소실)! 적당한 처리 방법을 찾아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d64a3-4429-407f-9422-15b705d83338",
   "metadata": {},
   "source": [
    "- 이진화 (binary) 이미지 만들기\n",
    "  - 픽셀값이 0과 1(255)로 구성\n",
    "  - 구글링 춘식이 이미지 다운받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44378d-5520-49c5-b1a3-340f2e4c9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chun.png 그레이스케일 출력!\n",
    "chun = cv2.imread('./data/chun.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 이진화 처리\n",
    "# 색상공간 변형: cvtColor()\n",
    "# 이진화로 변경: threshold(이미지, 임계값/경계값, 255, cv2.THRESH_BINARY)\n",
    "_, chun_thr = cv2.threshold(chun, 190, 255, cv2.THRESH_BINARY)\n",
    "print(chun_thr) # tuple: (사용자 정의한 임계값, 바뀐 이미지 데이터 배열)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(chun, cmap='gray')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(chun_thr, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "print(chun.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458c94d-784d-4e98-9e92-ea8642a2f772",
   "metadata": {},
   "source": [
    "- cv2.threshold(img, threshold_value, value, flag)\n",
    "\n",
    "  - img : Grayscale 이미지\n",
    "\n",
    "  - threshold_value : 픽셀 임계값 (0과 1로 나누기 위한 기준값)\n",
    "\n",
    "  - value : 임계값보다 클 때 적용되는 값\n",
    "\n",
    "  - flag : 임계값 적용 방법\n",
    "\n",
    "    - cv2.THRESH_BINARY : 임계값보다 픽셀값이 크면 value, 아니면 0을 할당\n",
    "\n",
    "    - cv2.THRESH_BINARY_INV : 임계값보다 픽셀값이 크면 0, 아니면 value를 할당  (cv2.THRESH_BINARY 반대)\n",
    "\n",
    "    - cv2.THRESH_TRUNC : 임계값보다 큰 픽셀 값은 모두 임계값, 아니면 픽셀값은 변경되지 않음 (이미지 밝기 조절에 사용, 밝은 영역을 어둡게 만들어 세부 정보 잘 드러나게)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3665be-d4cd-40e7-a58e-d857b95a2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.THRESH_BINARY_INV : THRESH_BINARY 반대 이미지\n",
    "\n",
    "chun = cv2.imread('./data/chun.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, thr = cv2.threshold(chun, 190, 255, cv2.THRESH_BINARY)\n",
    "_, thr_inv = cv2.threshold(chun, 190, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('gray')\n",
    "plt.imshow(chun, cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('binary')\n",
    "plt.imshow(thr, cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('binary inverse')\n",
    "plt.imshow(thr_inv, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "print(chun.shape)\n",
    "\n",
    "# 0~255 픽셀정보가 표현됨\n",
    "# 0: 검은색\n",
    "# 255: 흰색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daaf63e-8c07-4646-9403-1c798faf95ee",
   "metadata": {},
   "source": [
    "- 자동으로 임계값 찾아주는 기능 적용하기\n",
    "    - Otsu의 이진화: 이미지의 히스토그램을 분석하여(이미지 픽셀 정보의 밀도와 분산) 최적의 임계값을 자동으로 결정하는 이진화 기법(방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2fd92-0809-4e6b-9812-5abe20a421c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chun.shape)\n",
    "\n",
    "print(chun.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de114f2f-1d44-4697-a27d-969c86605cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chun = cv2.imread('./data/chun.png',cv2.IMREAD_GRAYSCALE)\n",
    "# 히스토그램 그려보기\n",
    "plt.hist(chun.reshape(-1))  # 가지고 있는 모든 데이터의 개수만큼 1차원으로 표현\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eaef45-4c0f-41d6-8e50-1fc4506bdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chun = cv2.imread('./data/chun.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 자동으로 임계값을 찾고, 이진화 처리 이미지 결과 출력 확인\n",
    "thr_val, chun_thr = cv2.threshold(chun, 0,255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "print('오츠의 임계값:', thr_val)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('chun'); plt.axis('off')\n",
    "plt.imshow(chun, cmap='gray')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Otsu binary'); plt.axis('off')\n",
    "plt.imshow(chun_thr, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a0ac4-d78e-451e-bf45-b9b4958007e0",
   "metadata": {},
   "source": [
    "#### 이미지 텍스트 to 텍스트\n",
    "- OCR : 광학 문자 인식, 텍스트 이미지를 기계가 읽을 수 있는 텍스트 포맷(문자열)으로 반환하는 과정\n",
    "- Tesseract API 활용\n",
    "- 깃허브 사이트 접근하여 실행 파일 다운로드\n",
    "- 코드상으로 환경에서도 설치 진행\n",
    "- 시스템 환경변수 경로 연결\n",
    "- notebook 내부 import\n",
    "- https://github.com/UB-Mannheim/tesseract/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a8321-f079-423a-a847-4ad6a1c9e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe257b-51ad-405c-8779-9bc2ff570d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "# r : 뒤에 오는 문자열을 그대로 기억\n",
    "# 환경 변수 설정\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab6e01-36b9-4b98-8f25-3d1340d7424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_img.png\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./data/text_img.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa25073-1693-4611-8f6a-6a968c848846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img 내부에 있는 영어문장 출력!\n",
    "import pytesseract as pytt\n",
    "\n",
    "text = pytt.image_to_string(img, lang='eng')  # 디폴트 'eng' 값\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613abec-12ce-435a-88d8-bc4ee72719e1",
   "metadata": {},
   "source": [
    "- 수기로 작성한 주문서 내용을 디지털화 시킬 때, OCR을 자주 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3df96-5fdf-4fb4-8485-f30dbaed43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어\n",
    "kor_img = cv2.imread('./data/kor_img.png')\n",
    "text = pytt.image_to_string(kor_img, lang='kor')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66fa92-7cb3-47ff-9445-19176fe4b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_kor = cv2.imread('./data/cat_kor.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(cat_kor, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "x1, y1 = 40, 115  # 좌측 상단 모서리의 좌표\n",
    "x2, y2 = 300, 170  # 우측 하단 모서리의 좌표\n",
    "cropped_image = cat_kor[y1:y2, x1:x2]\n",
    "\n",
    "plt.imshow(cropped_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "text2 = pytt.image_to_string(cropped_image, lang='kor')\n",
    "print(text2)\n",
    "\n",
    "# 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631c99f-dd89-48c9-af71-26702a437186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동으로 임계값을 찾고, 이진화 처리 이미지 결과 출력 확인\n",
    "_, thr = cv2.threshold(cropped_image, 235, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(thr, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "text3 = pytt.image_to_string(thr, lang='kor')\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac042f-df44-40d4-8e00-a3985bad9e72",
   "metadata": {},
   "source": [
    "- 왜 ㅎㅎ이 붙는지..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e85de-5265-4c16-8414-e9aaa0f1af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 텍스트 인식률을 높이려면\n",
    "# 1) 이미지 색상공간 변형, 잘라내기(중요한 부분에 접근(인덱싱, 슬라이싱)), 블러처리(노이즈 제거)\n",
    "# 2) pytesseract 도구만 사용하는게 아니라, 다른 인식률이 높은 ocr, api, 모델을 서칭 후 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154fcae-bc8a-4664-8cb1-3b8a7076f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_tag 숫자와 한국어 명확하게 인식하여 추출하기!\n",
    "car = cv2.imread(\"./data/car_tag.png\",cv2.IMREAD_GRAYSCALE)\n",
    "_,thr_car = cv2.threshold(car, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "plt.imshow(thr_car ,cmap = \"gray\")\n",
    "\n",
    "text_car = pytt.image_to_string(thr_car, lang = \"kor\")\n",
    "print(text_car)\n",
    "\n",
    "# 1- | 52가 3108\n",
    "# 2- 중요한 영역에 조금 더 집중되게 해보자! crop\n",
    "\n",
    "_, thr_car2 = cv2.threshold(car[25:120, 60:520], 30, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(thr_car2 ,cmap = \"gray\")\n",
    "\n",
    "text_car2 = pytt.image_to_string(thr_car2, lang = \"kor\")\n",
    "print(text_car2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f38560-d6bf-4250-a132-4cbf94a0c0b3",
   "metadata": {},
   "source": [
    "#### 가우시안 필터를 통한 블러 처리기능\n",
    "- 이미지 블러처리(사소한 노이즈를 제거하는 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8bee0-3aae-41cb-a475-d71ce723d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 이미지 읽기\n",
    "img = cv2.imread(\"./data/car_tag.png\")\n",
    " \n",
    "# 이미지 전처리\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0) # 가우시안 필터를 통한 블러 처리기능\n",
    "# _, thr1 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "_,thr1 = cv2.threshold(blur, 160, 255, cv2.THRESH_BINARY_INV)\n",
    " \n",
    "# OCR 수행\n",
    "text = pytesseract.image_to_string(thr1[:], lang='kor')\n",
    " \n",
    "# 결과 출력\n",
    "print('인식 결과:', text)\n",
    " \n",
    "# 이미지 및 결과 시각화\n",
    "plt.title('gray'); plt.imshow(gray, cmap='gray'); plt.show()\n",
    "plt.title('blur'); plt.imshow(blur, cmap='gray'); plt.show()\n",
    "plt.title(f'thr:{_}'); plt.imshow(thr1, cmap='gray'); plt.show()\n",
    "plt.title(f'thr:{_}_crop'); plt.imshow(thr1[22:120, 60:520], cmap='gray'); plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35c6e1-2bfb-40c5-aa53-3b24ce78cd9a",
   "metadata": {},
   "source": [
    "- 버전 문제 해결하면 해당 코드에서 7 -> 가 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188cd7d-8580-4f0e-9c7e-821dc4ab369f",
   "metadata": {},
   "source": [
    "- Hugging Face\n",
    "    - image to text 과제를 수행하는 모델을 찾아서 활용!\n",
    "    - 허깅페이스 관련 모듈 설치가 필요(환경셋팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1787a99-e17c-438a-a2ce-26eebda8c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe 통해서 텍스트 추출하는 코드\n",
    "# 이미지 전처리 추가 (상황에 따라 옵션)\n",
    "# 허깅페이스 모델을 사용할 경우 cv2 배열 이미지 실행x\n",
    "# -- 이미지 자체(png, jpg) 실행o\n",
    "# --> pipe(대상이미지, 넘파이 배열 이미지x)\n",
    "\n",
    "# 원하는 부분을 크롭\n",
    "# 1. cv2 -> 허깅모델x\n",
    "# 2. cv2 배열크롭 -> 이미지 자체로 형식 변경(PIL) -> 허깅모델o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3805096-93b0-46bd-8ab1-5554d87a0e82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_imaging' from 'PIL' (C:\\Users\\lgdxschool2\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use a pipeline as a high-level helper\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from PIL import Image\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage-to-text\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam-lucid/trocr-small-korean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\transformers\\utils\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     31\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\transformers\\utils\\chat_template_utils.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m     jinja2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\PIL\\Image.py:97\u001b[0m\n\u001b[0;32m     88\u001b[0m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    100\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_imaging' from 'PIL' (C:\\Users\\lgdxschool2\\anaconda3\\envs\\opencv_study\\Lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "# from PIL import Image\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=\"team-lucid/trocr-small-korean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb171c9-7245-49d5-b07e-fc802eefcae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# car_img = cv2.imread('./data/car.png', cv2.IMREAD_GRAYSCALE)\n",
    "# car_img_crop= car_img[40:140,105:600]\n",
    "\n",
    "# car_img_crop= Image.fromarray(car_img_crop)\n",
    "# plt.imshow(car_img_crop, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c4f41-1818-4aea-ad1a-bac0b478c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 전처리한 이미지를 다시 출력\n",
    "# pipe(cat_imag_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
