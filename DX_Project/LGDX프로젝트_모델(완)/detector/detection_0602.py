# detector/detection.py
import os
import time
import cv2
import requests
import numpy as np
from datetime import datetime
from pathlib import Path
from ultralytics import YOLO
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import google.generativeai as genai
import re
import warnings
import json
import glob
import base64
 
# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore', category=UserWarning)
 
# í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
SERVER_URL     = os.getenv("SERVER_URL", "http://localhost:8000")
API_EVENT_EP   = f"{SERVER_URL}/event"
 
# API í‚¤ ì§ì ‘ ì„¤ì •
GOOGLE_API_KEY = "API key change"
genai.configure(api_key=GOOGLE_API_KEY)
LLM = genai.GenerativeModel(model_name="models/gemini-2.5-flash-preview-05-20")
 
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[1]
 
# ===== ì…ë ¥ ì†ŒìŠ¤ ì„¤ì • =====
# ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Trueë¡œ ë³€ê²½
# ì˜ìƒ íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´ USE_CAMERA = Falseë¡œ ì„¤ì •í•˜ê³  VIDEO_PATH ì§€ì •
USE_CAMERA = False  # True: ì¹´ë©”ë¼ ì‚¬ìš©, False: ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©
CAMERA_ID = 0  # ì¹´ë©”ë¼ ì‚¬ìš© ì‹œ ì¹´ë©”ë¼ ID
VIDEO_PATH = "videos/dog_tearPaper.mp4"  # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
 
# ===== íŒŒë¼ë¯¸í„° ì„¤ì • =====
"""
[ì˜ìƒ ì²˜ë¦¬ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
FRAME_SKIP = 5    # ëª‡ í”„ë ˆì„ë‹¹ 1ë²ˆ ì²˜ë¦¬í• ì§€ ì„¤ì •
                  # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬)
                  # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ìì£¼ ì²´í¬í•˜ì§€ë§Œ ì²˜ë¦¬ ë¶€í•˜ê°€ ì¦ê°€
                  # ê°’ì´ í´ìˆ˜ë¡ ì²˜ë¦¬ëŠ” ë¹ ë¥´ì§€ë§Œ ë†“ì¹˜ëŠ” í–‰ë™ì´ ë§ì•„ì§ˆ ìˆ˜ ìˆìŒ
                  # ê¶Œì¥ ë²”ìœ„: 3~10
 
WINDOW_SIZE = 5    # í•œ ë²ˆì— ë¶„ì„í•  í”„ë ˆì„ ë¬¶ìŒ í¬ê¸°
                   # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ë¬¶ìŒìœ¼ë¡œ ë¶„ì„
                   # FRAME_SKIPê³¼ ì—°ê³„ë˜ì–´ ì‹¤ì œ ì‹œê°„ ê³„ì‚°ë¨
                   # í˜„ì¬ ì„¤ì •: 5í”„ë ˆì„ Ã— 5í”„ë ˆì„ ê°„ê²© = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„
 
DETECTION_WINDOWS = 5    # ì´ìƒí–‰ë™ ê°ì§€ë¥¼ ìœ„í•´ ì²´í¬í•  ìœˆë„ìš° ìˆ˜
                        # ì˜ˆ: 5ë¡œ ì„¤ì • ì‹œ 5ë²ˆì˜ ì—°ì†ëœ ìœˆë„ìš° ì²´í¬
                        # í˜„ì¬ ì„¤ì •: 5ë²ˆ Ã— 0.8ì´ˆ = ì•½ 4ì´ˆ ë™ì•ˆì˜ í–‰ë™ íŒ¨í„´ ì²´í¬
 
BUFFER_SECONDS = 4     # ì œë¯¸ë‹ˆ ë¶„ì„ ë° DB ì €ì¥ì„ ìœ„í•œ ì˜ìƒ ê¸¸ì´(ì´ˆ)
                      # ì œë¯¸ë‹ˆì— ë³´ë‚¼ ì˜ìƒê³¼ DBì— ì €ì¥í•  ì˜ìƒì˜ ê¸¸ì´
                      # ê°’ì´ í¬ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
                      # ê¶Œì¥ ë²”ìœ„: 3~5ì´ˆ
 
FPS = 30.0            # ê¸°ë³¸ FPS ì„¤ì •
                      # ëŒ€ë¶€ë¶„ì˜ ì¹´ë©”ë¼/ì˜ìƒì˜ ê¸°ë³¸ê°’ì´ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”
 
MAX_FRAMES = int(FPS * BUFFER_SECONDS)  # ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
                                       # ìë™ ê³„ì‚°ë˜ë¯€ë¡œ ìˆ˜ì • ë¶ˆí•„ìš”
                                       # í˜„ì¬ ì„¤ì •: 30fps Ã— 4ì´ˆ = 120í”„ë ˆì„
 
[ë¯¼ê°ë„ ê´€ë ¨ íŒŒë¼ë¯¸í„°]
STD_MULTIPLIER = 0.5   # ì´ìƒí–‰ë™ ê°ì§€ ë¯¼ê°ë„
                      # ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ë¯¼ê°í•˜ê²Œ ê°ì§€
                      # ê°’ì´ í´ìˆ˜ë¡ í™•ì‹¤í•œ ì´ìƒí–‰ë™ë§Œ ê°ì§€
                      # ê¶Œì¥ ë²”ìœ„: 0.3~1.0
 
IF_CONTAM = 0.2       # IsolationForest ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
LOF_CONTAM = 0.2      # LocalOutlierFactor ëª¨ë¸ì˜ ì´ìƒì¹˜ ë¹„ìœ¨
                      # ë‘ ê°’ì´ í´ìˆ˜ë¡ ë” ë§ì€ í–‰ë™ì„ ì´ìƒí–‰ë™ìœ¼ë¡œ íŒë‹¨
                      # ê¶Œì¥ ë²”ìœ„: 0.1~0.3
 
[ì‹¤ì œ ì‹œê°„ ê³„ì‚° ì˜ˆì‹œ]
í˜„ì¬ ì„¤ì • ê¸°ì¤€:
1. í”„ë ˆì„ ì²˜ë¦¬: 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ â†’ 1ì´ˆì— 6ë²ˆ ì²˜ë¦¬ (30fps ê¸°ì¤€)
2. í–‰ë™ ë¶„ì„: 5í”„ë ˆì„ Ã— 5ë²ˆ = 25í”„ë ˆì„(ì•½ 0.8ì´ˆ) ë‹¨ìœ„ë¡œ ë¶„ì„
3. ì´ìƒí–‰ë™ ê°ì§€: 5ë²ˆì˜ ì—°ì†ëœ ë¶„ì„ = ì•½ 4ì´ˆ ë™ì•ˆì˜ íŒ¨í„´ ì²´í¬
4. ì˜ìƒ ì €ì¥: ê°ì§€ í›„ 4ì´ˆ ë¶„ëŸ‰ ì €ì¥ ë° ë¶„ì„
 
ì„¤ì • ë³€ê²½ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ë¹ ë¥¸ ê°ì§€ê°€ í•„ìš”í•˜ë©´: FRAME_SKIPê³¼ WINDOW_SIZEë¥¼ ì¤„ì„
2. ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•˜ë©´: BUFFER_SECONDSë¥¼ ëŠ˜ë¦¼
3. ì €ì¥ ìš©ëŸ‰ ì ˆì•½ì´ í•„ìš”í•˜ë©´: FRAME_SKIPì„ ëŠ˜ë¦¼
"""
 
FRAME_SKIP         = 5    # 5í”„ë ˆì„ë‹¹ 1í”„ë ˆì„ ì²˜ë¦¬
WINDOW_SIZE        = 5    # ì´ìƒí–‰ë™ ê°ì§€ë¥¼ ìœ„í•œ ìœˆë„ìš° í¬ê¸° (5í”„ë ˆì„)
DETECTION_WINDOWS  = 5    # í•„ìš”í•œ ê°ì§€ íšŸìˆ˜ (5ë²ˆ)
ALLOWED_NORMAL     = 1    # í—ˆìš©ë˜ëŠ” ì •ìƒ í–‰ë™ íšŸìˆ˜
FPS               = 30.0  # ê¸°ë³¸ FPS
BUFFER_SECONDS    = 5     # ì €ì¥í•  ì˜ìƒ ê¸¸ì´ (ì´ˆ)
MAX_FRAMES        = int(FPS * BUFFER_SECONDS)  # ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
STD_MULTIPLIER    = 0.5   # í‘œì¤€í¸ì°¨ ë°°ìˆ˜ (ë¯¼ê°ë„)
IF_CONTAM         = 0.2   # IsolationForest contamination
LOF_CONTAM        = 0.2   # LocalOutlierFactor contamination
LOF_NEIGHBORS     = 4     # LocalOutlierFactor neighbors
 
# Gemini í”„ë¡¬í”„íŠ¸ â€“ 0~4ë‹¨ê³„ ëª…ì‹œ
dog_name = "ë³„ì´"
PROMPT = f"""ë„ˆëŠ” ê°•ì•„ì§€ì˜ ì´ìƒí–‰ë™ì„ ê´€ì°°í•˜ëŠ” ìˆ˜ì˜ì‚¬ì•¼. ê°•ì•„ì§€ {dog_name}ì˜ í˜„ì¬ í–‰ë™ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
ê°•ì•„ì§€ì˜ ìì„¸ì™€ ì›€ì§ì„ì„ ê¸°ë°˜ìœ¼ë¡œ í–‰ë™ì„ í•´ì„í•˜ê³ , ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
 
ì‘ë‹µ í˜•ì‹:
1. í˜„ì¬ í–‰ë™ ì„¤ëª… (1ì¤„)
2. ì‹¬ê°ë„: [0-3]ë‹¨ê³„
- 0ë‹¨ê³„: ì •ìƒì ì¸ í–‰ë™ (í‰ì˜¨, íœ´ì‹, ì¼ìƒì  í™œë™)
- 1ë‹¨ê³„: ì£¼ì˜ ê´€ì°° í•„ìš” (ê³¼ë„í•œ ì›€ì§ì„, ë¶ˆì•ˆí•œ ì§•í›„)
- 2ë‹¨ê³„: ê²½ë¯¸í•œ ë¬¸ì œ í–‰ë™ (ë°˜ë³µì ì¸ ì´ìƒ í–‰ë™)
- 3ë‹¨ê³„: ì‹¬ê°í•œ ë¬¸ì œ í–‰ë™ ë˜ëŠ” ìœ„í—˜ ìƒí™© (ê³µê²©ì„±, ìí•´ ìœ„í—˜, ì¦‰ê° ì¡°ì¹˜ í•„ìš”)
3. ì‹¬ê°ë„ì— ë”°ë¥¸ ëŒ€ì²˜ ë°©ë²• (1-2ì¤„)
4. ì‹¬ê°ë„ê°€ 0ë‹¨ê³„ì¼ ê²½ìš° ê°•ì•„ì§€ê°€ ë¬´ìŠ¨ í–‰ë™ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.
* 3ë‹¨ê³„ ì´ìƒì¼ ê²½ìš° ì‘ë‹µì„ **êµµì€ ê¸€ì”¨**ë¡œ í‘œì‹œ
* ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ì˜ˆì˜ì  í‘œí˜„ì€ ìƒëµ
* ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” íŒŒì•…ì´ ì–´ë ¤ì›Œë„ ìµœëŒ€í•œ íŒŒì•…í•´ì„œ í–‰ë™ ë¶„ì„í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
* ë°˜ë“œì‹œ ë‹¨ê³„ë¥¼ ìˆ«ìë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš” (ì˜ˆ: '2ë‹¨ê³„' ë˜ëŠ” 'ë‹¨ê³„: 2')"""
 
# ëª¨ë¸ ë¡œë“œ
MODEL_PATH = PROJECT_ROOT / "dog_pose_model.pt"
print(f"ëª¨ë¸ íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
yolo      = YOLO(str(MODEL_PATH))
if_model  = IsolationForest(contamination=IF_CONTAM, random_state=42)
lof_model = LocalOutlierFactor(n_neighbors=LOF_NEIGHBORS, contamination=LOF_CONTAM, novelty=True)
 
def z_norm(a):
    return (a - a.mean()) / (a.std() or 1.0)
 
def post_event(timestamp, stage, summary, frames, fps, dog_name="í…ŒìŠ¤íŠ¸ê°•ì•„ì§€"):
    """
    ì„œë²„ /event ë¡œ ì´ë²¤íŠ¸ ë°ì´í„° ì „ì†¡ ë° ì €ì¥ í™•ì¸
    """
    try:
        data = {
            'dog_name': dog_name,
            'timestamp': timestamp,
            'stage': str(stage),
            'summary': summary
        }
       
        # ì˜ìƒ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if frames is not None and len(frames) > 0:
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_name = f"{current_time}.mp4"
            temp_path = os.path.join('temp_videos', video_name)
           
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs('temp_videos', exist_ok=True)
           
            print(f"\nğŸ“ ì„ì‹œ íŒŒì¼ ìƒì„± ì¤‘: {temp_path}")
           
            # í•´ìƒë„ 1280x720ìœ¼ë¡œ ì„¤ì •
            resized_frames = []
            for frame in frames:
                resized = cv2.resize(frame, (1280, 720))
                resized_frames.append(resized)
           
            h, w = resized_frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_path, fourcc, fps/FRAME_SKIP, (w, h), True)
           
            for frame in resized_frames:
                out.write(frame)
            out.release()
            out = None  # ëª…ì‹œì ìœ¼ë¡œ ê°ì²´ í•´ì œ
            time.sleep(0.1)  # íŒŒì¼ì´ ì™„ì „íˆ ë‹«í ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
           
            if not os.path.exists(temp_path):
                print("âš ï¸ ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                return None
               
            file_size = os.path.getsize(temp_path)
            print(f"ğŸ“¤ ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡ ì¤‘... (íŒŒì¼ í¬ê¸°: {file_size/1024:.1f}KB)")
           
            # multipart/form-data í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡
            response = None
            with open(temp_path, 'rb') as f:
                files = {'video_data': (video_name, f, 'video/mp4')}
                try:
                    r = requests.post(API_EVENT_EP, data=data, files=files, timeout=30)
                    print(f"   - ì„œë²„ ì‘ë‹µ ì½”ë“œ: {r.status_code}")
                    print(f"   - ì„œë²„ ì‘ë‹µ ë‚´ìš©: {r.text}")
                   
                    if r.status_code == 200:
                        response = r.json()
                except Exception as e:
                    print(f"âš ï¸ HTTP ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
                    return None
           
            # íŒŒì¼ í•¸ë“¤ì´ ë‹«íŒ í›„ì— DB ì €ì¥ í™•ì¸ ë° íŒŒì¼ ì‚­ì œ
            if response and response.get('id'):
                print("âœ… DB ì €ì¥ ì™„ë£Œ!")
                try:
                    os.remove(temp_path)
                    print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œë¨: {temp_path}")
                except Exception as e:
                    print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
                return response
           
            print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: ì„œë²„ ì‘ë‹µ í™•ì¸ í•„ìš”")
            return None
        else:
            # ì˜ìƒ ì—†ì´ DBì—ë§Œ ì €ì¥
            print("ğŸ“¤ ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡ ì¤‘... (ì˜ìƒ ì œì™¸)")
            r = requests.post(API_EVENT_EP, data=data, timeout=30)
           
        print(f"   - ì„œë²„ ì‘ë‹µ ì½”ë“œ: {r.status_code}")
        print(f"   - ì„œë²„ ì‘ë‹µ ë‚´ìš©: {r.text}")
       
        if r.status_code == 200:
            response = r.json()
            if response.get('id'):
                return response
       
        print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: ì„œë²„ ì‘ë‹µ í™•ì¸ í•„ìš”")
        return None
           
    except Exception as e:
        print(f"âš ï¸ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return None
 
def analyze_with_gemini(frames_count, dog_name: str):
    """
    Gemini AIë¥¼ ì‚¬ìš©í•œ í–‰ë™ ë¶„ì„
   
    ë§¤ê°œë³€ìˆ˜:
    - frames_count: ë¶„ì„í•  í”„ë ˆì„ ìˆ˜
   
    ë°˜í™˜ê°’:
    - stage: í–‰ë™ ë‹¨ê³„ (0-4)
    - text: ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    try:
        print("\nğŸ¤– Gemini ë¶„ì„ ì‹œì‘...")
       
        # ë¶„ì„í•  ì˜ìƒ ì°¾ê¸°
        gemini_videos = sorted(glob.glob('gemini_videos/*.mp4'))
        if not gemini_videos:
            print("âš ï¸ ë¶„ì„í•  ì˜ìƒ ì—†ìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ ì—†ìŒ"
           
        latest_video = gemini_videos[-1]
        print(f"ğŸ“ ë¶„ì„í•  ì˜ìƒ: {latest_video}")
       
        if not os.path.exists(latest_video):
            print(f"âš ï¸ ì˜ìƒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {latest_video}")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ íŒŒì¼ ì—†ìŒ"
           
        file_size = os.path.getsize(latest_video)
        print(f"ğŸ“Š ì˜ìƒ íŒŒì¼ í¬ê¸°: {file_size/1024:.1f}KB")
       
        if file_size == 0:
            print("âš ï¸ ì˜ìƒ íŒŒì¼ì´ ë¹„ì–´ìˆìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ë¹ˆ ì˜ìƒ íŒŒì¼"
       
        print("ğŸ”„ ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        video_file = genai.upload_file(path=latest_video)
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {video_file.name}")
       
        print("â³ ì˜ìƒ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
        retry_count = 0
        while video_file.state.name == "PROCESSING" and retry_count < 10:
            time.sleep(0.5)
            video_file = genai.get_file(video_file.name)
            retry_count += 1
            print(f"   - ìƒíƒœ: {video_file.state.name} (ì‹œë„: {retry_count})")
           
        if video_file.state.name == "FAILED" or retry_count >= 10:
            print(f"âš ï¸ ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨ (ìƒíƒœ: {video_file.state.name})")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì˜ìƒ ì²˜ë¦¬ ì˜¤ë¥˜"
 
        print("\nğŸ“ í”„ë¡¬í”„íŠ¸ ì „ì†¡...")
       
        resp = LLM.generate_content([PROMPT, video_file])
       
        if not resp:
            print("âš ï¸ ì‘ë‹µ ì—†ìŒ")
            return 0, "ë¶„ì„ ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ"
           
        text = resp.text.strip()
        print("\nâœ… ë¶„ì„ ì™„ë£Œ:")
        print(text)
       
        stage = 0
        if "ë‹¨ê³„" in text:
            stage_match = re.search(r'(\d+)ë‹¨ê³„|ë‹¨ê³„[:\s]*(\d+)|ì‹¬ê°ë„[:\s]*(\d+)', text)
            if stage_match:
                stage = int(stage_match.group(1) or stage_match.group(2) or stage_match.group(3))
       
        if stage < 0 or stage > 4:
            print(f"âš ï¸ ì˜ëª»ëœ ë‹¨ê³„ ê°’ ({stage})")
            stage = 0
           
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"- ë‹¨ê³„: {stage}")
        print(f"- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
       
        return stage, text
       
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜:")
        print(f"- ìœ í˜•: {type(e).__name__}")
        print(f"- ë‚´ìš©: {str(e)}")
        import traceback
        print(f"- ìƒì„¸:\n{traceback.format_exc()}")
        return 0, f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
 
def process_video():
    """
    ì˜ìƒ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ì½ì–´ ì²˜ë¦¬
    """
    print("ğŸ¥ ì˜ìƒ ì†ŒìŠ¤ ì´ˆê¸°í™” ì¤‘...")
   
    if USE_CAMERA:
        # ì¹´ë©”ë¼ ëª¨ë“œ
        cap = cv2.VideoCapture(CAMERA_ID, cv2.CAP_DSHOW)
        if not cap.isOpened():
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        print(f"âœ… ì¹´ë©”ë¼ {CAMERA_ID} ì—°ê²°ë¨")
    else:
        # ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œ
        video_path = str(PROJECT_ROOT / VIDEO_PATH)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return
        print(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œë¨: {video_path}")
   
    # í•´ìƒë„ ì„¤ì • (ì¹´ë©”ë¼ ëª¨ë“œì¼ ë•Œë§Œ)
    if USE_CAMERA:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
   
    # ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS) or FPS
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
   
    print(f"- í•´ìƒë„: {width}x{height}")
    print(f"- FPS: {fps:.1f}")
    print(f"- í”„ë ˆì„ ìŠ¤í‚µ: {FRAME_SKIP} (ì²˜ë¦¬ FPS: {fps/FRAME_SKIP:.1f})")
    print(f"- ë²„í¼ í¬ê¸°: {BUFFER_SECONDS}ì´ˆ ({MAX_FRAMES} í”„ë ˆì„)")
    if not USE_CAMERA:
        print(f"- ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
        print(f"- ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {total_frames/fps:.1f}ì´ˆ")
 
    # Gemini ë¹„ë””ì˜¤ ì €ì¥ í´ë” ìƒì„±
    os.makedirs('gemini_videos', exist_ok=True)
   
    # ì´ˆê¸°í™”
    features = []  # íŠ¹ì§•ì  ë²„í¼
    frames_vis = []  # ì‹œê°í™”ëœ í”„ë ˆì„ ë²„í¼
    frames_original = []  # ì›ë³¸ í”„ë ˆì„ ë²„í¼
    frame_idxs = []  # í”„ë ˆì„ ì¸ë±ìŠ¤ ë²„í¼
    frame_times = []  # í”„ë ˆì„ ì‹œê°„ ë²„í¼ ì¶”ê°€
    frame_no = 0
    last_event_time = 0
    is_recording = False
    current_stage = 0
    current_summary = ""
    recording_start_time = 0
   
    # ì´ìƒí–‰ë™ ê°ì§€ ê´€ë ¨ ë³€ìˆ˜
    abnormal_windows = []  # ê° ìœˆë„ìš°ì˜ ì´ìƒí–‰ë™ ì—¬ë¶€ë¥¼ ì €ì¥
    continuous_detection = False  # ì—°ì† ê°ì§€ ìƒíƒœ
   
   
    cv2.namedWindow("Dog Pose Detection", cv2.WINDOW_NORMAL)
 
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âœ… ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
            break
           
        if frame is None or frame.size == 0:
            print("âš ï¸ ë¹ˆ í”„ë ˆì„ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            continue
           
        frame_no += 1
        current_time = time.time()
       
        # ì§„í–‰ë¥  í‘œì‹œ (ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œì¼ ë•Œë§Œ)
        if not USE_CAMERA and frame_no % 30 == 0:
            progress = (frame_no / total_frames) * 100
            print(f"\rì§„í–‰ë¥ : {progress:.1f}%", end="")
       
        if frame_no % FRAME_SKIP != 0:
            continue
 
        # YOLOë¡œ í¬ì¦ˆ ì˜ˆì¸¡ ë° ì‹œê°í™”
        result = yolo.predict(frame, conf=0.7, verbose=False)[0]
        vis = result.plot()
 
        if result.keypoints is not None and len(result.keypoints.data) > 0:
            kpts = result.keypoints.data[0]
            if kpts.shape[0] == 24:
                pelvis = kpts[14][:2]
                l_sh, r_sh = kpts[11][:2], kpts[12][:2]
                scale = np.linalg.norm(l_sh - r_sh) or 1.0
 
                feat = []
                for x, y, v in kpts:
                    if v < 0.5:
                        feat += [0.0, 0.0]
                    else:
                        feat += [(x - pelvis[0]) / scale,
                                (y - pelvis[1]) / scale]
                features.append(feat)
                frames_vis.append(vis.copy())
                frames_original.append(frame.copy())  # ì›ë³¸ í”„ë ˆì„ ì €ì¥
                frame_idxs.append(frame_no)
               
                # íŠ¹ì§•ì ì´ ì¶©ë¶„íˆ ëª¨ì´ë©´ ì´ìƒí–‰ë™ ê°ì§€
                if len(features) >= WINDOW_SIZE:
                    X = np.array(features[-WINDOW_SIZE:])
                    if_model.fit(X)
                    lof_model.fit(X)
                    if_scores = if_model.decision_function(X)
                    lof_scores = lof_model.decision_function(X)
                    combined = (z_norm(if_scores) + z_norm(lof_scores)) / 2.0
                   
                    # ì„ê³„ì¹˜ ê³„ì‚° ë° ì´ìƒí–‰ë™ íŒì •
                    threshold = combined.mean() - STD_MULTIPLIER * combined.std()
                    is_abnormal = combined[-1] < threshold
 
                    # í˜„ì¬ ìœˆë„ìš°ì˜ ì´ìƒí–‰ë™ ì—¬ë¶€ ì €ì¥
                    abnormal_windows.append(is_abnormal)
                    if len(abnormal_windows) > DETECTION_WINDOWS:
                        abnormal_windows.pop(0)
 
                    # ì—°ì†ëœ ì´ìƒí–‰ë™ ì²´í¬
                    if len(abnormal_windows) == DETECTION_WINDOWS:
                        abnormal_count = sum(abnormal_windows)
                        if abnormal_count >= (DETECTION_WINDOWS - ALLOWED_NORMAL) and not continuous_detection:
                            continuous_detection = True
                            is_recording = True
                            recording_start_time = time.time()  # ë…¹í™” ì‹œì‘ ì‹œê°„ ê¸°ë¡
                            frames_vis = []  # ë²„í¼ ì´ˆê¸°í™”
                            frames_original = []  # ì›ë³¸ í”„ë ˆì„ ë²„í¼ë„ ì´ˆê¸°í™”
                            print("\nğŸ” ì—°ì†ì ì¸ ì´ìƒí–‰ë™ ê°ì§€ - ì˜ìƒ ìˆ˜ì§‘ ì‹œì‘")
                   
                    # ì˜ìƒ ìˆ˜ì§‘ ë° ë¶„ì„
                    if is_recording:
                        current_time = time.time()
                        frame_times.append(current_time)  # í˜„ì¬ í”„ë ˆì„ ì‹œê°„ ì €ì¥
                        current_duration = current_time - recording_start_time
                       
                        # í”„ë ˆì„ ìˆ˜ì§‘
                        frames_original.append(frame.copy())
                       
                        # ëª©í‘œ ì‹œê°„ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸
                        if current_duration >= BUFFER_SECONDS:
                            print(f"\nğŸ“¹ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ:")
                            print(f"   - ìˆ˜ì§‘ëœ í”„ë ˆì„ ìˆ˜: {len(frames_original)}")
                            print(f"   - ëª©í‘œ í”„ë ˆì„ ìˆ˜: {MAX_FRAMES}")
                            print(f"   - ì‹¤ì œ ìˆ˜ì§‘ ì‹œê°„: {current_duration:.2f}ì´ˆ")
                            print(f"   - ëª©í‘œ ìˆ˜ì§‘ ì‹œê°„: {BUFFER_SECONDS}ì´ˆ")
                           
                            # ì •í™•í•œ ì‹œê°„ì— ë§ì¶° í”„ë ˆì„ ìë¥´ê¸°
                            target_duration = BUFFER_SECONDS
                            valid_frames = []
                            valid_duration = 0
                           
                            # í”„ë ˆì„ ì„ íƒ (ì •í™•í•œ ì‹œê°„ì— ë§ì¶”ê¸°)
                            for i, t in enumerate(frame_times):
                                frame_duration = t - recording_start_time
                                if frame_duration <= target_duration:
                                    valid_frames.append(frames_original[i])
                                    valid_duration = frame_duration
                           
                            # í”„ë ˆì„ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê²½ê³ 
                            if len(valid_frames) < MAX_FRAMES * 0.5:  # ëª©í‘œ í”„ë ˆì„ì˜ 50% ë¯¸ë§Œ
                                print(f"âš ï¸ ê²½ê³ : í”„ë ˆì„ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ ({len(valid_frames)} < {MAX_FRAMES})")
                           
                            try:
                                # Gemini ë¶„ì„ìš© ì„ì‹œ ì˜ìƒ ìƒì„±
                                os.makedirs("gemini_videos", exist_ok=True)
                               
                                # ì´ì „ ë¶„ì„ ì˜ìƒ ì •ë¦¬
                                for old_file in glob.glob('gemini_videos/*.mp4'):
                                    try:
                                        os.remove(old_file)
                                        print(f"ğŸ—‘ï¸ ì´ì „ ì˜ìƒ ì‚­ì œ: {old_file}")
                                    except Exception as e:
                                        print(f"âš ï¸ ì´ì „ ì˜ìƒ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
                               
                                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                                temp_video_path = os.path.join("gemini_videos", f"temp_{timestamp_str}.mp4")
                                print(f"\nğŸ’¾ ë¶„ì„ìš© ì˜ìƒ ì €ì¥ ì¤‘: {temp_video_path}")
                               
                                # í”„ë ˆì„ ë ˆì´íŠ¸ ì¡°ì •
                                target_fps = fps / FRAME_SKIP
                                h, w = valid_frames[0].shape[:2]
                               
                                # ì½”ë± ì„¤ì •
                                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                                out = cv2.VideoWriter(temp_video_path, fourcc, target_fps, (w, h))
                               
                                if not out.isOpened():
                                    print("âš ï¸ ì˜ìƒ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                                    raise Exception("VideoWriter ì´ˆê¸°í™” ì‹¤íŒ¨")
                               
                                # í”„ë ˆì„ ì €ì¥
                                frames_written = 0
                                for frame in valid_frames:
                                    out.write(frame)
                                    frames_written += 1
                               
                                out.release()
                                time.sleep(0.5)  # íŒŒì¼ì´ ì™„ì „íˆ ì €ì¥ë˜ë„ë¡ ëŒ€ê¸°
                               
                                if not os.path.exists(temp_video_path):
                                    raise Exception("ì˜ìƒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                                   
                                file_size = os.path.getsize(temp_video_path)
                                print(f"âœ… ì˜ìƒ ì €ì¥ ì™„ë£Œ:")
                                print(f"   - ì €ì¥ëœ í”„ë ˆì„: {frames_written}")
                                print(f"   - íŒŒì¼ í¬ê¸°: {file_size/1024:.1f}KB")
                               
                            except Exception as e:
                                print(f"âŒ ì˜ìƒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
                                print(f"   - ìœ í˜•: {type(e).__name__}")
                                print(f"   - ë‚´ìš©: {str(e)}")
                                import traceback
                                print(f"   - ìƒì„¸:\n{traceback.format_exc()}")
                                return
                           
                            # ì œë¯¸ë‹ˆ ë¶„ì„ ì‹¤í–‰
                            analysis_start_time = time.time()
                            current_stage, current_summary = analyze_with_gemini(len(valid_frames))
                            print(f"â±ï¸ ì œë¯¸ë‹ˆ ë¶„ì„ ì‹œê°„: {time.time() - analysis_start_time:.2f}ì´ˆ")
                           
                            # ì´ë²¤íŠ¸ ì €ì¥ (ëª¨ë“  ë‹¨ê³„ì— ëŒ€í•´ ì˜ìƒ ì €ì¥)
                            print(f"\nğŸ’¾ ì´ë²¤íŠ¸ ì €ì¥ ì‹œë„ ì¤‘... (ë‹¨ê³„: {current_stage})")
                           
                            # ì˜ìƒ ì €ì¥ì„ ìœ„í•œ í”„ë ˆì„ ì¤€ë¹„
                            target_frames = int(fps * BUFFER_SECONDS / FRAME_SKIP)  # ëª©í‘œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
                           
                            if len(valid_frames) > target_frames:
                                # í”„ë ˆì„ì´ ë§ìœ¼ë©´ ê· ë“±í•˜ê²Œ ì„ íƒ
                                step = len(valid_frames) / target_frames
                                selected_indices = [int(i * step) for i in range(target_frames)]
                                selected_frames = [valid_frames[i] for i in selected_indices]
                            else:
                                # í”„ë ˆì„ì´ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë³µì œ
                                selected_frames = valid_frames.copy()
                                while len(selected_frames) < target_frames:
                                    selected_frames.append(valid_frames[-1])
                           
                            result = post_event(datetime.now().isoformat(),
                                              current_stage,
                                              current_summary,
                                              selected_frames,
                                              fps,
                                              dog_name="í…ŒìŠ¤íŠ¸ê°•ì•„ì§€")
                           
                            if result:
                                print(f"âœ… DB ì €ì¥ ì™„ë£Œ!")
                                print(f"   - í–‰ë™ ë‹¨ê³„: {current_stage}")
                                print(f"   - ì˜ìƒ í¬í•¨: ì˜ˆ")
                            else:
                                print("âš ï¸ DB ì €ì¥ ì‹¤íŒ¨")
                           
                            # ìƒíƒœ ì´ˆê¸°í™”
                            frames_vis = []
                            frames_original = []
                            frame_times = []  # ì‹œê°„ ë²„í¼ë„ ì´ˆê¸°í™”
                            is_recording = False
                            continuous_detection = False
                            abnormal_windows = []
                            current_stage = 0
                            current_summary = ""
 
                    # ë²„í¼ ê´€ë¦¬
                    if len(features) > WINDOW_SIZE:
                        features.pop(0)
                    if len(frames_vis) > MAX_FRAMES:
                        frames_vis.pop(0)
                    if len(frames_original) > MAX_FRAMES:  # ì›ë³¸ í”„ë ˆì„ ë²„í¼ ê´€ë¦¬
                        frames_original.pop(0)
                    if len(frame_idxs) > MAX_FRAMES:
                        frame_idxs.pop(0)
 
        cv2.imshow("Dog Pose Detection", vis)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
            break
 
    cap.release()
    cv2.destroyAllWindows()
 
if __name__ == "__main__":
    process_video()
